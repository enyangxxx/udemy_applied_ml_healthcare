{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction using Neural Networks\n",
    "\n",
    "This project will focus on predicting heart disease using neural networks. Based on attributes such as blood pressure, cholestoral levels, heart rate, and other characteristic attributes, patients will be classified for their heart disease diagnosis. This project utilizes a dataset of 303 patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.4 (v3.7.4:e09359112e, Jul  8 2019, 14:54:52) \n",
      "[Clang 6.0 (clang-600.0.57)]\n",
      "Pandas: 1.0.1\n",
      "Numpy: 1.18.3\n",
      "Sklearn: 0.22.1\n",
      "Matplotlib: 3.1.1\n",
      "Keras: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import keras\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Pandas: {}'.format(pd.__version__))\n",
    "print('Numpy: {}'.format(np.__version__))\n",
    "print('Sklearn: {}'.format(sklearn.__version__))\n",
    "print('Matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('Keras: {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the Dataset\n",
    "\n",
    "There are overall 76 attributes, including age, sex, resting blood pressure, cholestoral levels, echocardiogram data, exercise habits, and many others. We focus on a subset of 14 attributes. Let's talk about each feature and the target output more concretely, the source of information for the following section is https://towardsdatascience.com/heart-disease-prediction-73468d630cfc.\n",
    "\n",
    "* age: The age of patient at the time of data entry. Age is the most important risk factor in developing cardiovascular or heart diseases, with approximately a tripling of risk with each decade of life. Coronary fatty streaks can begin to form in adolescence. It is estimated that 82 percent of people who die of coronary heart disease are 65 and older. Simultaneously, the risk of stroke doubles every decade after age 55.\n",
    "\n",
    "* sex: equivalent to gender - 1 = male / 0 = female. Men are at greater risk of heart disease than pre-menopausal women. Once past menopause, it has been argued that a woman’s risk is similar to a man’s although more recent data from the WHO and UN disputes this. If a female has diabetes, she is more likely to develop heart disease than a male with diabetes.\n",
    "\n",
    "* cp: Chest pain type - 1 = typical angina / 2 = atypical angina / 3 = non—anginal pain / 4 = asymptotic. Angina is chest pain or discomfort caused when your heart muscle doesn’t get enough oxygen-rich blood. It may feel like pressure or squeezing in your chest. The discomfort also can occur in your shoulders, arms, neck, jaw, or back.\n",
    "\n",
    "* restbps: Resting blood pressure in mmHg. Over time, high blood pressure can damage arteries that feed your heart. High blood pressure that occurs with other conditions, such as obesity, high cholesterol or diabetes, increases your risk even more.\n",
    "\n",
    "* chol: Serum cholesterol in mg/dl. A high level of low-density lipoprotein (LDL) cholesterol (the “bad” cholesterol) is most likely to narrow arteries. However, a high level of high-density lipoprotein (HDL) cholesterol (the “good” cholesterol) lowers your risk of a heart attack.\n",
    "\n",
    "* fbs: Fasting blood sugar - compares the fasting blood sugar value of an individual with 120mg/dl. If fasting blood sugar > 120mg/dl then: 1 (true), else: 0 (false). Not producing enough of a hormone secreted by your pancreas (insulin) or not responding to insulin properly causes your body’s blood sugar levels to rise, increasing your risk of a heart attack.\n",
    "\n",
    "* restecg: Resting ECG - 0 = normal / 1 = having ST-T wave abnormality / 2 = left ventricular hyperthrophy. You may need an ECG test if you have risk factors for heart disease such as high blood pressure, or symptoms such as palpitations or chest pain. Or you may need it if you already have heart disease.\n",
    "\n",
    "* thalach: Max heart rate achieved. The increase in cardiovascular risk, associated with the acceleration of heart rate, was comparable to the increase in risk observed with high blood pressure. It has been shown that an increase in heart rate by 10 beats per minute was associated with an increase in the risk of cardiac death by at least 20%, and this increase in the risk is similar to the one observed with an increase in systolic blood pressure by 10 mm Hg.\n",
    "\n",
    "* exang: Exercise induced angina - 1 = yes / 0 = no. The pain or discomfort associated with angina usually feels tight, gripping or squeezing, and can vary from mild to severe. Angina is usually felt in the center of your chest but may spread to either or both of your shoulders, or your back, neck, jaw or arm. It can even be felt in your hands.\n",
    "\n",
    "* oldpeak: ST depression induced by exercise relative to rest. \n",
    "\n",
    "* slope: Peak exercise ST segment - 1 = upsloping / 2 = flat / 3 = downsloping\n",
    "\n",
    "* ca: Number of major vessels (0–3) colored by flourosopy\n",
    "\n",
    "* thal: Thalassemia - 3 = normal / 6 = fixed defect / 7 = reversible defect\n",
    "\n",
    "* class: Target output - 0 = no heart disease / 1-4 = present heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  restbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0    145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0    160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0    120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0    130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0    130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...      ...    ...  ...      ...      ...    ...      ...   \n",
       "298  45.0  1.0  1.0    110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0    144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0    130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0    130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0    138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  class  \n",
       "0      3.0  0.0  6.0      0  \n",
       "1      2.0  3.0  3.0      2  \n",
       "2      2.0  2.0  7.0      1  \n",
       "3      3.0  0.0  3.0      0  \n",
       "4      1.0  0.0  3.0      0  \n",
       "..     ...  ...  ...    ...  \n",
       "298    2.0  0.0  7.0      1  \n",
       "299    2.0  2.0  7.0      2  \n",
       "300    2.0  1.0  7.0      3  \n",
       "301    2.0  1.0  3.0      1  \n",
       "302    1.0    ?  3.0      0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"processed.cleveland.data\"\n",
    "column_names = ['age', 'sex', 'cp', 'restbps', 'chol',\n",
    "                'fbs', 'restecg', 'thalach', 'exang', \n",
    "                'oldpeak', 'slope', 'ca', 'thal',\n",
    "                'class']\n",
    "\n",
    "cleveland = pd.read_csv(url, names=column_names)\n",
    "cleveland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check if there are missing data, indicated with a question mark, as you can see in the row with index 302. They must be converted into `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  restbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0    145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0    160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0    120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0    130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0    130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...      ...    ...  ...      ...      ...    ...      ...   \n",
       "298  45.0  1.0  1.0    110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0    144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0    130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0    130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0    138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  class  \n",
       "0      3.0  0.0  6.0      0  \n",
       "1      2.0  3.0  3.0      2  \n",
       "2      2.0  2.0  7.0      1  \n",
       "3      3.0  0.0  3.0      0  \n",
       "4      1.0  0.0  3.0      0  \n",
       "..     ...  ...  ...    ...  \n",
       "298    2.0  0.0  7.0      1  \n",
       "299    2.0  2.0  7.0      2  \n",
       "300    2.0  1.0  7.0      3  \n",
       "301    2.0  1.0  3.0      1  \n",
       "302    1.0  NaN  3.0      0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cleveland[~cleveland.isin(['?'])]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 rows could be removed. We have 2 features (`ca` and `thal`) which are not numeric data. They need to be converted into numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age        float64\n",
      "sex        float64\n",
      "cp         float64\n",
      "restbps    float64\n",
      "chol       float64\n",
      "fbs        float64\n",
      "restecg    float64\n",
      "thalach    float64\n",
      "exang      float64\n",
      "oldpeak    float64\n",
      "slope      float64\n",
      "ca          object\n",
      "thal        object\n",
      "class        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        float64\n",
       "sex        float64\n",
       "cp         float64\n",
       "restbps    float64\n",
       "chol       float64\n",
       "fbs        float64\n",
       "restecg    float64\n",
       "thalach    float64\n",
       "exang      float64\n",
       "oldpeak    float64\n",
       "slope      float64\n",
       "ca         float64\n",
       "thal       float64\n",
       "class        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(pd.to_numeric)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, it can be helpful and interesting looking into statistics of each feature.\n",
    "\n",
    "* The oldest person is 77, while the youngest person is 29 years old. The average age is 54 with a standard deviation of 9. 75% of the individuals are younger than 61 years old.\n",
    "* There are more males in the dataset than females.\n",
    "* It is very unhealthy to have a resting blood pressure of 200 at maximum, as well as a cholesterol of 564, regardless of the likelihood.\n",
    "* The fasting blood sugar is 0.14 on average, while its range is between 0 and 1.\n",
    "\n",
    "There are more observations, I will leave it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.542088</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>3.158249</td>\n",
       "      <td>131.693603</td>\n",
       "      <td>247.350168</td>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>149.599327</td>\n",
       "      <td>0.326599</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>1.602694</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>4.730640</td>\n",
       "      <td>0.946128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.049736</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.964859</td>\n",
       "      <td>17.762806</td>\n",
       "      <td>51.997583</td>\n",
       "      <td>0.352474</td>\n",
       "      <td>0.994914</td>\n",
       "      <td>22.941562</td>\n",
       "      <td>0.469761</td>\n",
       "      <td>1.166123</td>\n",
       "      <td>0.618187</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>1.938629</td>\n",
       "      <td>1.234551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp     restbps        chol         fbs  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean    54.542088    0.676768    3.158249  131.693603  247.350168    0.144781   \n",
       "std      9.049736    0.468500    0.964859   17.762806   51.997583    0.352474   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  243.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  276.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean     0.996633  149.599327    0.326599    1.055556    1.602694    0.676768   \n",
       "std      0.994914   22.941562    0.469761    1.166123    0.618187    0.938965   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000  133.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal       class  \n",
       "count  297.000000  297.000000  \n",
       "mean     4.730640    0.946128  \n",
       "std      1.938629    1.234551  \n",
       "min      3.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    2.000000  \n",
       "max      7.000000    4.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the distribution gives us more information. The occurrence of positive class seems to equal the accumulated occurrence of negative classes. Additionally, the most features seem to be categorical according to their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist(figsize = (12, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Training and Testing Datasets\n",
    "\n",
    "The class values in this dataset contain multiple types of heart disease with values ranging from 0 (healthy) to 4 (severe heart disease). We will need to convert our class data to categorical labels by applying one-hot encoding. For example, the label 2 will become [0, 0, 1, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (237, 13)\n",
      "y_train shape: (237,)\n",
      "X_test shape: (60, 13)\n",
      "y_test shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X = np.array(data.drop(['class'], 1))\n",
    "y = np.array(data['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 5)\n",
      "Example of one-hot encoding: [0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, num_classes=None)\n",
    "Y_test = to_categorical(y_test, num_classes=None)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(\"Example of one-hot encoding: {}\".format(Y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building and Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 25        \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a total number of 173 parameters, we see that the accuracy and loss are not fluctuating after approx. 55 epochs, means that the model is not able to be furtherly optimized. I tried to make the model a bit more complex by adding more new neurons, but it didn't improve significantly. The achieved training accuracy is around 64% only, while the loss is around 0.90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "237/237 [==============================] - 0s 593us/step - loss: 1.6142 - accuracy: 0.1308\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 0s 282us/step - loss: 1.5259 - accuracy: 0.1013\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 1.5007 - accuracy: 0.4346\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 1.4755 - accuracy: 0.5527\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 1.4508 - accuracy: 0.5527\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 0s 183us/step - loss: 1.4304 - accuracy: 0.5527\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 1.4103 - accuracy: 0.5527\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 0s 174us/step - loss: 1.3881 - accuracy: 0.5527\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 0s 155us/step - loss: 1.3752 - accuracy: 0.5527\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 0s 150us/step - loss: 1.3249 - accuracy: 0.5527\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 0s 184us/step - loss: 1.3045 - accuracy: 0.5527\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 0s 153us/step - loss: 1.2742 - accuracy: 0.5527\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 0s 185us/step - loss: 1.2582 - accuracy: 0.5527\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 0s 159us/step - loss: 1.2500 - accuracy: 0.5527\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 1.2264 - accuracy: 0.5527\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 1.2090 - accuracy: 0.5527\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 1.1953 - accuracy: 0.5527\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 0s 177us/step - loss: 1.1757 - accuracy: 0.5527\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 0s 187us/step - loss: 1.1593 - accuracy: 0.5527\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 0s 179us/step - loss: 1.1547 - accuracy: 0.5527\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 1.1518 - accuracy: 0.5527\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.1185 - accuracy: 0.5527\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 1.1039 - accuracy: 0.5527\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 1.1239 - accuracy: 0.5527\n",
      "Epoch 25/100\n",
      "237/237 [==============================] - 0s 178us/step - loss: 1.1014 - accuracy: 0.5527\n",
      "Epoch 26/100\n",
      "237/237 [==============================] - 0s 158us/step - loss: 1.0825 - accuracy: 0.5527\n",
      "Epoch 27/100\n",
      "237/237 [==============================] - 0s 179us/step - loss: 1.0850 - accuracy: 0.5527\n",
      "Epoch 28/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 1.0649 - accuracy: 0.5527\n",
      "Epoch 29/100\n",
      "237/237 [==============================] - 0s 156us/step - loss: 1.0606 - accuracy: 0.5527\n",
      "Epoch 30/100\n",
      "237/237 [==============================] - 0s 155us/step - loss: 1.0515 - accuracy: 0.5527\n",
      "Epoch 31/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 1.0570 - accuracy: 0.5527\n",
      "Epoch 32/100\n",
      "237/237 [==============================] - 0s 160us/step - loss: 1.0436 - accuracy: 0.5527\n",
      "Epoch 33/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.0511 - accuracy: 0.5527\n",
      "Epoch 34/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 1.0346 - accuracy: 0.5527\n",
      "Epoch 35/100\n",
      "237/237 [==============================] - 0s 159us/step - loss: 1.0316 - accuracy: 0.5527\n",
      "Epoch 36/100\n",
      "237/237 [==============================] - 0s 155us/step - loss: 1.0337 - accuracy: 0.5527\n",
      "Epoch 37/100\n",
      "237/237 [==============================] - 0s 161us/step - loss: 1.0507 - accuracy: 0.5527\n",
      "Epoch 38/100\n",
      "237/237 [==============================] - 0s 177us/step - loss: 1.0339 - accuracy: 0.5527\n",
      "Epoch 39/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 1.0182 - accuracy: 0.5907\n",
      "Epoch 40/100\n",
      "237/237 [==============================] - 0s 191us/step - loss: 1.0090 - accuracy: 0.6076\n",
      "Epoch 41/100\n",
      "237/237 [==============================] - 0s 155us/step - loss: 1.0189 - accuracy: 0.6076\n",
      "Epoch 42/100\n",
      "237/237 [==============================] - 0s 184us/step - loss: 1.0093 - accuracy: 0.6160\n",
      "Epoch 43/100\n",
      "237/237 [==============================] - 0s 156us/step - loss: 1.0076 - accuracy: 0.5992\n",
      "Epoch 44/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 1.0082 - accuracy: 0.6160\n",
      "Epoch 45/100\n",
      "237/237 [==============================] - 0s 155us/step - loss: 1.0082 - accuracy: 0.6118\n",
      "Epoch 46/100\n",
      "237/237 [==============================] - 0s 172us/step - loss: 1.0006 - accuracy: 0.6160\n",
      "Epoch 47/100\n",
      "237/237 [==============================] - 0s 150us/step - loss: 0.9893 - accuracy: 0.6203\n",
      "Epoch 48/100\n",
      "237/237 [==============================] - 0s 193us/step - loss: 0.9909 - accuracy: 0.6203\n",
      "Epoch 49/100\n",
      "237/237 [==============================] - 0s 158us/step - loss: 0.9886 - accuracy: 0.6160\n",
      "Epoch 50/100\n",
      "237/237 [==============================] - 0s 148us/step - loss: 1.0110 - accuracy: 0.6203\n",
      "Epoch 51/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 0.9992 - accuracy: 0.6245\n",
      "Epoch 52/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9840 - accuracy: 0.6160\n",
      "Epoch 53/100\n",
      "237/237 [==============================] - 0s 187us/step - loss: 0.9724 - accuracy: 0.6287\n",
      "Epoch 54/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9793 - accuracy: 0.6203\n",
      "Epoch 55/100\n",
      "237/237 [==============================] - 0s 196us/step - loss: 0.9914 - accuracy: 0.6329\n",
      "Epoch 56/100\n",
      "237/237 [==============================] - 0s 179us/step - loss: 1.0033 - accuracy: 0.6160\n",
      "Epoch 57/100\n",
      "237/237 [==============================] - 0s 172us/step - loss: 0.9766 - accuracy: 0.6203\n",
      "Epoch 58/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 0.9653 - accuracy: 0.6203\n",
      "Epoch 59/100\n",
      "237/237 [==============================] - 0s 159us/step - loss: 0.9651 - accuracy: 0.6287\n",
      "Epoch 60/100\n",
      "237/237 [==============================] - 0s 171us/step - loss: 0.9725 - accuracy: 0.6287\n",
      "Epoch 61/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 0.9733 - accuracy: 0.6160\n",
      "Epoch 62/100\n",
      "237/237 [==============================] - 0s 177us/step - loss: 0.9663 - accuracy: 0.6245\n",
      "Epoch 63/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 0.9535 - accuracy: 0.6245\n",
      "Epoch 64/100\n",
      "237/237 [==============================] - 0s 187us/step - loss: 0.9579 - accuracy: 0.6414\n",
      "Epoch 65/100\n",
      "237/237 [==============================] - 0s 178us/step - loss: 0.9653 - accuracy: 0.6245\n",
      "Epoch 66/100\n",
      "237/237 [==============================] - 0s 172us/step - loss: 0.9876 - accuracy: 0.6245\n",
      "Epoch 67/100\n",
      "237/237 [==============================] - 0s 231us/step - loss: 0.9469 - accuracy: 0.6287\n",
      "Epoch 68/100\n",
      "237/237 [==============================] - 0s 233us/step - loss: 0.9579 - accuracy: 0.6287\n",
      "Epoch 69/100\n",
      "237/237 [==============================] - 0s 218us/step - loss: 0.9580 - accuracy: 0.6371\n",
      "Epoch 70/100\n",
      "237/237 [==============================] - 0s 194us/step - loss: 0.9462 - accuracy: 0.6203\n",
      "Epoch 71/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 0.9423 - accuracy: 0.6245\n",
      "Epoch 72/100\n",
      "237/237 [==============================] - 0s 184us/step - loss: 0.9623 - accuracy: 0.6329\n",
      "Epoch 73/100\n",
      "237/237 [==============================] - 0s 160us/step - loss: 0.9412 - accuracy: 0.6329\n",
      "Epoch 74/100\n",
      "237/237 [==============================] - 0s 159us/step - loss: 0.9393 - accuracy: 0.6287\n",
      "Epoch 75/100\n",
      "237/237 [==============================] - 0s 183us/step - loss: 0.9325 - accuracy: 0.6329\n",
      "Epoch 76/100\n",
      "237/237 [==============================] - 0s 181us/step - loss: 0.9382 - accuracy: 0.6245\n",
      "Epoch 77/100\n",
      "237/237 [==============================] - 0s 214us/step - loss: 0.9297 - accuracy: 0.6329\n",
      "Epoch 78/100\n",
      "237/237 [==============================] - 0s 210us/step - loss: 0.9317 - accuracy: 0.6371\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 0s 182us/step - loss: 0.9339 - accuracy: 0.6245\n",
      "Epoch 80/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 0.9243 - accuracy: 0.6329\n",
      "Epoch 81/100\n",
      "237/237 [==============================] - 0s 155us/step - loss: 0.9234 - accuracy: 0.6414\n",
      "Epoch 82/100\n",
      "237/237 [==============================] - 0s 140us/step - loss: 0.9196 - accuracy: 0.6371\n",
      "Epoch 83/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 0.9223 - accuracy: 0.6245\n",
      "Epoch 84/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 0.9670 - accuracy: 0.6329\n",
      "Epoch 85/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 0.9211 - accuracy: 0.6287\n",
      "Epoch 86/100\n",
      "237/237 [==============================] - 0s 195us/step - loss: 0.9141 - accuracy: 0.6371\n",
      "Epoch 87/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 0.9247 - accuracy: 0.6287\n",
      "Epoch 88/100\n",
      "237/237 [==============================] - 0s 145us/step - loss: 0.9175 - accuracy: 0.6414\n",
      "Epoch 89/100\n",
      "237/237 [==============================] - 0s 148us/step - loss: 0.9212 - accuracy: 0.6371\n",
      "Epoch 90/100\n",
      "237/237 [==============================] - 0s 143us/step - loss: 0.9205 - accuracy: 0.6329\n",
      "Epoch 91/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 0.9186 - accuracy: 0.6329\n",
      "Epoch 92/100\n",
      "237/237 [==============================] - 0s 143us/step - loss: 0.9127 - accuracy: 0.6329\n",
      "Epoch 93/100\n",
      "237/237 [==============================] - 0s 145us/step - loss: 0.9109 - accuracy: 0.6287\n",
      "Epoch 94/100\n",
      "237/237 [==============================] - 0s 153us/step - loss: 0.9114 - accuracy: 0.6371\n",
      "Epoch 95/100\n",
      "237/237 [==============================] - 0s 148us/step - loss: 0.9142 - accuracy: 0.6287\n",
      "Epoch 96/100\n",
      "237/237 [==============================] - 0s 185us/step - loss: 0.9250 - accuracy: 0.6498\n",
      "Epoch 97/100\n",
      "237/237 [==============================] - 0s 270us/step - loss: 0.9040 - accuracy: 0.6329\n",
      "Epoch 98/100\n",
      "237/237 [==============================] - 0s 142us/step - loss: 0.9252 - accuracy: 0.6245\n",
      "Epoch 99/100\n",
      "237/237 [==============================] - 0s 147us/step - loss: 0.9472 - accuracy: 0.6287\n",
      "Epoch 100/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 0.9032 - accuracy: 0.6414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x136451d50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Improving Results - A Binary Classification Problem\n",
    "\n",
    "Thinking logically, a binary classification task is surely easier to train for. Let's simplify the problem by converting the data to a binary classification problem - heart disease or no heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "Y_train_binary = y_train.copy()\n",
    "Y_test_binary = y_test.copy()\n",
    "\n",
    "Y_train_binary[Y_train_binary > 0] = 1\n",
    "Y_test_binary[Y_test_binary > 0] = 1\n",
    "\n",
    "print(Y_train_binary[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_binary_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "binary_model = create_binary_model()\n",
    "\n",
    "print(binary_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see way better results for training data than before, as I expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "237/237 [==============================] - 0s 873us/step - loss: 0.6972 - accuracy: 0.5232\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 0s 257us/step - loss: 0.6810 - accuracy: 0.5654\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 0s 199us/step - loss: 0.6726 - accuracy: 0.6245\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 0s 178us/step - loss: 0.6578 - accuracy: 0.5949\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 0.6362 - accuracy: 0.6878\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 0s 174us/step - loss: 0.6047 - accuracy: 0.6793\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.5925 - accuracy: 0.6793\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 0.5592 - accuracy: 0.7300\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 0.5610 - accuracy: 0.7131\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 0.5357 - accuracy: 0.7553\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.5292 - accuracy: 0.7257\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 0.5044 - accuracy: 0.7426\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 0s 184us/step - loss: 0.5069 - accuracy: 0.7384\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 0s 159us/step - loss: 0.4874 - accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 0.4836 - accuracy: 0.7722\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 0.4874 - accuracy: 0.7595\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 0s 190us/step - loss: 0.4608 - accuracy: 0.7764\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 0.4716 - accuracy: 0.7679\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 0.4531 - accuracy: 0.7932\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 0.4423 - accuracy: 0.7932\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 0.4408 - accuracy: 0.8017\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 0.4602 - accuracy: 0.7848\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 0s 187us/step - loss: 0.4920 - accuracy: 0.7764\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.4776 - accuracy: 0.7468\n",
      "Epoch 25/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 0.4392 - accuracy: 0.7806\n",
      "Epoch 26/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.4072 - accuracy: 0.7890\n",
      "Epoch 27/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 0.4164 - accuracy: 0.8059\n",
      "Epoch 28/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 0.4223 - accuracy: 0.8101\n",
      "Epoch 29/100\n",
      "237/237 [==============================] - 0s 184us/step - loss: 0.4282 - accuracy: 0.8059\n",
      "Epoch 30/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 0.4297 - accuracy: 0.7932\n",
      "Epoch 31/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4013 - accuracy: 0.8270\n",
      "Epoch 32/100\n",
      "237/237 [==============================] - 0s 158us/step - loss: 0.4005 - accuracy: 0.8143\n",
      "Epoch 33/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 0.3934 - accuracy: 0.8312\n",
      "Epoch 34/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 0.4055 - accuracy: 0.8354\n",
      "Epoch 35/100\n",
      "237/237 [==============================] - 0s 189us/step - loss: 0.3941 - accuracy: 0.8186\n",
      "Epoch 36/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 0.3936 - accuracy: 0.8439\n",
      "Epoch 37/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 0.3741 - accuracy: 0.8523\n",
      "Epoch 38/100\n",
      "237/237 [==============================] - 0s 172us/step - loss: 0.3950 - accuracy: 0.8059\n",
      "Epoch 39/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 0.3784 - accuracy: 0.8397\n",
      "Epoch 40/100\n",
      "237/237 [==============================] - 0s 318us/step - loss: 0.3772 - accuracy: 0.8523\n",
      "Epoch 41/100\n",
      "237/237 [==============================] - 0s 334us/step - loss: 0.3701 - accuracy: 0.8565\n",
      "Epoch 42/100\n",
      "237/237 [==============================] - 0s 223us/step - loss: 0.3678 - accuracy: 0.8608\n",
      "Epoch 43/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 0.3679 - accuracy: 0.8439\n",
      "Epoch 44/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 0.3618 - accuracy: 0.8734\n",
      "Epoch 45/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 0.3667 - accuracy: 0.8565\n",
      "Epoch 46/100\n",
      "237/237 [==============================] - 0s 165us/step - loss: 0.3633 - accuracy: 0.8650\n",
      "Epoch 47/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 0.3628 - accuracy: 0.8608\n",
      "Epoch 48/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 0.3727 - accuracy: 0.8734\n",
      "Epoch 49/100\n",
      "237/237 [==============================] - 0s 197us/step - loss: 0.3606 - accuracy: 0.8565\n",
      "Epoch 50/100\n",
      "237/237 [==============================] - 0s 195us/step - loss: 0.3571 - accuracy: 0.8692\n",
      "Epoch 51/100\n",
      "237/237 [==============================] - 0s 164us/step - loss: 0.3640 - accuracy: 0.8439\n",
      "Epoch 52/100\n",
      "237/237 [==============================] - 0s 228us/step - loss: 0.3677 - accuracy: 0.8608\n",
      "Epoch 53/100\n",
      "237/237 [==============================] - 0s 471us/step - loss: 0.4050 - accuracy: 0.8397\n",
      "Epoch 54/100\n",
      "237/237 [==============================] - 0s 198us/step - loss: 0.3692 - accuracy: 0.8650\n",
      "Epoch 55/100\n",
      "237/237 [==============================] - 0s 166us/step - loss: 0.3683 - accuracy: 0.8565\n",
      "Epoch 56/100\n",
      "237/237 [==============================] - 0s 158us/step - loss: 0.3583 - accuracy: 0.8692\n",
      "Epoch 57/100\n",
      "237/237 [==============================] - 0s 149us/step - loss: 0.3633 - accuracy: 0.8565\n",
      "Epoch 58/100\n",
      "237/237 [==============================] - 0s 147us/step - loss: 0.3507 - accuracy: 0.8734\n",
      "Epoch 59/100\n",
      "237/237 [==============================] - 0s 156us/step - loss: 0.3616 - accuracy: 0.8481\n",
      "Epoch 60/100\n",
      "237/237 [==============================] - 0s 151us/step - loss: 0.3736 - accuracy: 0.8608\n",
      "Epoch 61/100\n",
      "237/237 [==============================] - 0s 161us/step - loss: 0.3481 - accuracy: 0.8650\n",
      "Epoch 62/100\n",
      "237/237 [==============================] - 0s 167us/step - loss: 0.3720 - accuracy: 0.8523\n",
      "Epoch 63/100\n",
      "237/237 [==============================] - 0s 153us/step - loss: 0.3672 - accuracy: 0.8481\n",
      "Epoch 64/100\n",
      "237/237 [==============================] - 0s 159us/step - loss: 0.3649 - accuracy: 0.8776\n",
      "Epoch 65/100\n",
      "237/237 [==============================] - 0s 168us/step - loss: 0.3558 - accuracy: 0.8439\n",
      "Epoch 66/100\n",
      "237/237 [==============================] - 0s 421us/step - loss: 0.3530 - accuracy: 0.8692\n",
      "Epoch 67/100\n",
      "237/237 [==============================] - 0s 670us/step - loss: 0.3785 - accuracy: 0.8397\n",
      "Epoch 68/100\n",
      "237/237 [==============================] - 0s 688us/step - loss: 0.3916 - accuracy: 0.8439\n",
      "Epoch 69/100\n",
      "237/237 [==============================] - 0s 518us/step - loss: 0.3886 - accuracy: 0.8481\n",
      "Epoch 70/100\n",
      "237/237 [==============================] - 0s 209us/step - loss: 0.3638 - accuracy: 0.8650\n",
      "Epoch 71/100\n",
      "237/237 [==============================] - 0s 221us/step - loss: 0.4022 - accuracy: 0.8228\n",
      "Epoch 72/100\n",
      "237/237 [==============================] - 0s 194us/step - loss: 0.3546 - accuracy: 0.8481\n",
      "Epoch 73/100\n",
      "237/237 [==============================] - 0s 175us/step - loss: 0.3598 - accuracy: 0.8734\n",
      "Epoch 74/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 0.3527 - accuracy: 0.8692\n",
      "Epoch 75/100\n",
      "237/237 [==============================] - 0s 183us/step - loss: 0.3571 - accuracy: 0.8565\n",
      "Epoch 76/100\n",
      "237/237 [==============================] - 0s 176us/step - loss: 0.3645 - accuracy: 0.8565\n",
      "Epoch 77/100\n",
      "237/237 [==============================] - 0s 163us/step - loss: 0.3598 - accuracy: 0.8439\n",
      "Epoch 78/100\n",
      "237/237 [==============================] - 0s 403us/step - loss: 0.3465 - accuracy: 0.8776\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 0s 235us/step - loss: 0.3574 - accuracy: 0.8692\n",
      "Epoch 80/100\n",
      "237/237 [==============================] - 0s 334us/step - loss: 0.3422 - accuracy: 0.8776\n",
      "Epoch 81/100\n",
      "237/237 [==============================] - 0s 153us/step - loss: 0.3571 - accuracy: 0.8734\n",
      "Epoch 82/100\n",
      "237/237 [==============================] - 0s 157us/step - loss: 0.3578 - accuracy: 0.8439\n",
      "Epoch 83/100\n",
      "237/237 [==============================] - 0s 150us/step - loss: 0.3503 - accuracy: 0.8692\n",
      "Epoch 84/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 0.3541 - accuracy: 0.8776\n",
      "Epoch 85/100\n",
      "237/237 [==============================] - 0s 147us/step - loss: 0.3474 - accuracy: 0.8608\n",
      "Epoch 86/100\n",
      "237/237 [==============================] - 0s 148us/step - loss: 0.3743 - accuracy: 0.8523\n",
      "Epoch 87/100\n",
      "237/237 [==============================] - 0s 146us/step - loss: 0.3634 - accuracy: 0.8734\n",
      "Epoch 88/100\n",
      "237/237 [==============================] - 0s 148us/step - loss: 0.3484 - accuracy: 0.8776\n",
      "Epoch 89/100\n",
      "237/237 [==============================] - 0s 154us/step - loss: 0.3452 - accuracy: 0.8734\n",
      "Epoch 90/100\n",
      "237/237 [==============================] - 0s 148us/step - loss: 0.3536 - accuracy: 0.8650\n",
      "Epoch 91/100\n",
      "237/237 [==============================] - 0s 160us/step - loss: 0.3761 - accuracy: 0.8397\n",
      "Epoch 92/100\n",
      "237/237 [==============================] - 0s 187us/step - loss: 0.3681 - accuracy: 0.8565\n",
      "Epoch 93/100\n",
      "237/237 [==============================] - 0s 214us/step - loss: 0.3492 - accuracy: 0.8523\n",
      "Epoch 94/100\n",
      "237/237 [==============================] - 0s 173us/step - loss: 0.3605 - accuracy: 0.8481\n",
      "Epoch 95/100\n",
      "237/237 [==============================] - 0s 156us/step - loss: 0.3909 - accuracy: 0.8481\n",
      "Epoch 96/100\n",
      "237/237 [==============================] - 0s 173us/step - loss: 0.3783 - accuracy: 0.8397\n",
      "Epoch 97/100\n",
      "237/237 [==============================] - 0s 162us/step - loss: 0.3772 - accuracy: 0.8439\n",
      "Epoch 98/100\n",
      "237/237 [==============================] - 0s 399us/step - loss: 0.3533 - accuracy: 0.8692\n",
      "Epoch 99/100\n",
      "237/237 [==============================] - 0s 376us/step - loss: 0.3519 - accuracy: 0.8692\n",
      "Epoch 100/100\n",
      "237/237 [==============================] - 0s 161us/step - loss: 0.3555 - accuracy: 0.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1359134d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model.fit(X_train, Y_train_binary, epochs=100, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Results and Metrics\n",
    "\n",
    "The evaluation metrics should be applied on the testing dataset, verifying how well the models generalize to test data. The test accuracy for the multi-classifier is below the training accuracy. Having an accuracy of 50% is not satisfying, although it is better than guessing without knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Categorical Model\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.90      0.75        29\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.21      0.80      0.33         5\n",
      "\n",
      "    accuracy                           0.50        60\n",
      "   macro avg       0.22      0.42      0.27        60\n",
      "weighted avg       0.33      0.50      0.39        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/enyangEnv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "categorical_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print('Results for Categorical Model')\n",
    "print(accuracy_score(y_test, categorical_pred))\n",
    "print(classification_report(y_test, categorical_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary classifier achieves a better test accuracy, but looking at the precision and recall score, there are also tendencies observed for the positive and negative classes. The models which have been trained so far, are not really usable for serious purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Binary Model\n",
      "0.6833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.90      0.73        29\n",
      "           1       0.83      0.48      0.61        31\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.73      0.69      0.67        60\n",
      "weighted avg       0.73      0.68      0.67        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_pred = np.round(binary_model.predict(X_test)).astype(int)\n",
    "\n",
    "print('Results for Binary Model')\n",
    "print(accuracy_score(Y_test_binary, binary_pred))\n",
    "print(classification_report(Y_test_binary, binary_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Potential Follow-Up Tasks\n",
    "\n",
    "Maybe it would be a good way to reduce the number of features in order to simplify the learning for the model. How about applying the `SelectKBest()` class to extract top 10 best features, if we are not able to enlarge the dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
